{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MotEx.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+790fTxiuuo+7pUoB+Xnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndySAnker/fast-MotEx/blob/main/MotEx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First download anaconda"
      ],
      "metadata": {
        "id": "zsUH1SkNcXvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash \n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-latest-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n"
      ],
      "metadata": {
        "id": "Nj2xoZEFcnDb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download DiffPy-CMI"
      ],
      "metadata": {
        "id": "zdTwoCCteBbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!conda create -n diffpy -c defaults -c diffpy python=3.7 diffpy-cmi pandas --yes\n",
        "!cp -r /usr/local/envs/diffpy/lib/python3.7/site-packages/diffpy.srfit-3.0.0-py3.7.egg/diffpy/* /usr/local/envs/diffpy/lib/python3.7/site-packages/diffpy/\n",
        "!cp -r /usr/local/envs/diffpy/lib/python3.7/site-packages/diffpy.structure-3.0.1-py3.7.egg/diffpy/* /usr/local/envs/diffpy/lib/python3.7/site-packages/diffpy/\n",
        "!cp -r /usr/local/envs/diffpy/lib/python3.7/site-packages/diffpy.utils-3.0.0-py3.7.egg/diffpy/* /usr/local/envs/diffpy/lib/python3.7/site-packages/diffpy/\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, \"/usr/local/envs/diffpy/lib/python3.7/site-packages\")"
      ],
      "metadata": {
        "id": "2sQ-K82BcnFd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules and functions"
      ],
      "metadata": {
        "id": "l6-llHW5eIYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt-get install software-properties-common\n",
        "!sudo add-apt-repository ppa:ubuntu-toolchain-r/test\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install gcc-4.9\n",
        "!sudo apt-get upgrade libstdc++6"
      ],
      "metadata": {
        "id": "8UvtnS4cV2Tt",
        "outputId": "71532fd2-f076-4092-ada7-1211ae8ff080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.96.24.32.18).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            " Toolchain test builds; see https://wiki.ubuntu.com/ToolChain\n",
            "\n",
            " More info: https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test\n",
            "Press [ENTER] to continue or Ctrl-c to cancel adding it.\n",
            "\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:6 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic InRelease [20.8 kB]\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Get:14 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 Packages [50.4 kB]\n",
            "Fetched 71.1 kB in 1s (81.8 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package gcc-4.9 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "E: Package 'gcc-4.9' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  gcc-11-base libgcc-s1\n",
            "The following packages have been kept back:\n",
            "  lib32gcc1 lib32stdc++6 libcudnn8 libcudnn8-dev libnccl-dev libnccl2\n",
            "The following packages will be upgraded:\n",
            "  libatomic1 libcc1-0 libgcc1 libgomp1 libitm1 liblsan0 libobjc4 libquadmath0\n",
            "  libstdc++6 libtsan0\n",
            "10 upgraded, 2 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 1,536 kB of archives.\n",
            "After this operation, 1,227 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 gcc-11-base amd64 11.1.0-1ubuntu1~18.04.1 [19.0 kB]\n",
            "Get:2 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libgcc-s1 amd64 11.1.0-1ubuntu1~18.04.1 [41.8 kB]\n",
            "Get:3 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libgcc1 amd64 1:11.1.0-1ubuntu1~18.04.1 [41.7 kB]\n",
            "Get:4 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libstdc++6 amd64 11.1.0-1ubuntu1~18.04.1 [580 kB]\n",
            "Get:5 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libatomic1 amd64 11.1.0-1ubuntu1~18.04.1 [9,168 B]\n",
            "Get:6 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libcc1-0 amd64 11.1.0-1ubuntu1~18.04.1 [40.8 kB]\n",
            "Get:7 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libgomp1 amd64 11.1.0-1ubuntu1~18.04.1 [107 kB]\n",
            "Get:8 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libitm1 amd64 11.1.0-1ubuntu1~18.04.1 [26.1 kB]\n",
            "Get:9 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 liblsan0 amd64 11.1.0-1ubuntu1~18.04.1 [150 kB]\n",
            "Get:10 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libobjc4 amd64 11.1.0-1ubuntu1~18.04.1 [43.5 kB]\n",
            "Get:11 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libquadmath0 amd64 11.1.0-1ubuntu1~18.04.1 [145 kB]\n",
            "Get:12 http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu bionic/main amd64 libtsan0 amd64 11.1.0-1ubuntu1~18.04.1 [331 kB]\n",
            "Fetched 1,536 kB in 1s (2,863 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 12.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package gcc-11-base:amd64.\n",
            "(Reading database ... 159616 files and directories currently installed.)\n",
            "Preparing to unpack .../gcc-11-base_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking gcc-11-base:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up gcc-11-base:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libgcc-s1:amd64.\n",
            "(Reading database ... 159621 files and directories currently installed.)\n",
            "Preparing to unpack .../libgcc-s1_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libgcc-s1:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Replacing files in old package libgcc1:amd64 (1:8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libgcc-s1:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "(Reading database ... 159623 files and directories currently installed.)\n",
            "Preparing to unpack .../libgcc1_1%3a11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libgcc1 (1:11.1.0-1ubuntu1~18.04.1) over (1:8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libgcc1 (1:11.1.0-1ubuntu1~18.04.1) ...\n",
            "(Reading database ... 159624 files and directories currently installed.)\n",
            "Preparing to unpack .../libstdc++6_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libstdc++6:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libstdc++6:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "(Reading database ... 159624 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libatomic1_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libatomic1:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../1-libcc1-0_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libcc1-0:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../2-libgomp1_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libgomp1:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../3-libitm1_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libitm1:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../4-liblsan0_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking liblsan0:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../5-libobjc4_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libobjc4:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../6-libquadmath0_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libquadmath0:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Preparing to unpack .../7-libtsan0_11.1.0-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libtsan0:amd64 (11.1.0-1ubuntu1~18.04.1) over (8.4.0-1ubuntu1~18.04) ...\n",
            "Setting up libquadmath0:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up libgomp1:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up libatomic1:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up libcc1-0:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up libobjc4:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up libtsan0:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up liblsan0:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Setting up libitm1:amd64 (11.1.0-1ubuntu1~18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX"
      ],
      "metadata": {
        "id": "d8cMU8yVV8B3",
        "outputId": "24861eda-c237-497f-b695-e1d42c39e833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLIBCXX_3.4\n",
            "GLIBCXX_3.4.1\n",
            "GLIBCXX_3.4.2\n",
            "GLIBCXX_3.4.3\n",
            "GLIBCXX_3.4.4\n",
            "GLIBCXX_3.4.5\n",
            "GLIBCXX_3.4.6\n",
            "GLIBCXX_3.4.7\n",
            "GLIBCXX_3.4.8\n",
            "GLIBCXX_3.4.9\n",
            "GLIBCXX_3.4.10\n",
            "GLIBCXX_3.4.11\n",
            "GLIBCXX_3.4.12\n",
            "GLIBCXX_3.4.13\n",
            "GLIBCXX_3.4.14\n",
            "GLIBCXX_3.4.15\n",
            "GLIBCXX_3.4.16\n",
            "GLIBCXX_3.4.17\n",
            "GLIBCXX_3.4.18\n",
            "GLIBCXX_3.4.19\n",
            "GLIBCXX_3.4.20\n",
            "GLIBCXX_3.4.21\n",
            "GLIBCXX_3.4.22\n",
            "GLIBCXX_3.4.23\n",
            "GLIBCXX_3.4.24\n",
            "GLIBCXX_3.4.25\n",
            "GLIBCXX_3.4.26\n",
            "GLIBCXX_3.4.27\n",
            "GLIBCXX_3.4.28\n",
            "GLIBCXX_3.4.29\n",
            "GLIBCXX_DEBUG_MESSAGE_LENGTH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/AndySAnker/fast-MotEx.git\n",
        "!apt install ase\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm\n",
        "import time, random\n",
        "from scipy.optimize.minpack import leastsq\n",
        "from diffpy.Structure import Structure, Atom\n",
        "from diffpy.srfit.pdf import PDFContribution, PDFParser, PDFGenerator\n",
        "from diffpy.srfit.fitbase import FitRecipe, FitResults, Profile, FitContribution\n",
        "from diffpy.srreal.pdfcalculator import DebyePDFCalculator\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "from ase.io import read\n",
        "from google.colab import output, files\n",
        "\n",
        "random.seed(14)\n",
        "np.random.seed(14)"
      ],
      "metadata": {
        "id": "CXbklySJc0IL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def structure_catalogue_maker(Number_of_atoms):\n",
        "    \"\"\"Makes a catalogue of structures\"\"\"\n",
        "    \n",
        "    structure_catalogue = np.ones((Number_of_atoms,Number_of_atoms))\n",
        "    structure_catalogue[np.array([range(Number_of_atoms)]),np.array([range(Number_of_atoms)])] = 0\n",
        "    return structure_catalogue\n",
        "\n",
        "def Load(Experimental_Data, starting_model):\n",
        "    \"\"\"This function loads the data and structure\"\"\"\n",
        "    \n",
        "    # Get experimental data\n",
        "    for skip_row in range(100):\n",
        "        try:\n",
        "            Exp_data = np.loadtxt(Experimental_Data, skiprows=skip_row)\n",
        "        except ValueError:\n",
        "            continue\n",
        "    # Nyquist sampling the data by only using every 10nth datapoint\n",
        "    if Exp_data[1,0] - Exp_data[0,0] < 0.1:\n",
        "        Exp_r, Exp_Gr = Exp_data[::10,0], Exp_data[::10,1]\n",
        "    else:\n",
        "        Exp_r, Exp_Gr = Exp_data[:,0], Exp_data[:,1]\n",
        "    # Normalise data\n",
        "    Exp_Gr /= max(Exp_Gr)\n",
        "\n",
        "    # Read structure and divide it into two lists: Atoms we want to iterate (W) and atoms we do not iterate (O)\n",
        "    struct=[]\n",
        "    with open(starting_model, 'r') as fi:\n",
        "        for line in fi.readlines():\n",
        "            sep_line=line.strip('{}\\n\\r ').split()\n",
        "            if len(sep_line)==4: #  tillader andre informationer i xyz filen some ikke skal laeses\n",
        "                struct.append(sep_line)\n",
        "    elements=np.array(struct)[:,0]\n",
        "    xyz=(np.array(struct)[:,1:].astype(float))\n",
        "    \n",
        "    return Exp_r, Exp_Gr, elements, xyz\n",
        "\n",
        "def format_XYZ(starting_model, allowed_atoms):\n",
        "\t# Read structure and divide it into two lists: Atoms we want to iterate and atoms we do not iterate.\n",
        "\t# Save the file in this new format and get number of atoms that we iterate.\n",
        "\tpermutable_struct = []\n",
        "\tnonpermutable_struct = []\n",
        "\twith open(starting_model, 'r') as fi:\n",
        "\t\tfor line in fi.readlines():\n",
        "\t\t\tsep_line=line.strip('{}\\n\\r ').split()\n",
        "\t\t\tif len(sep_line)==4: #  tillader andre informationer i xyz filen some ikke skal laeses\n",
        "\t\t\t\tif sep_line[0] in allowed_atoms:\n",
        "\t\t\t\t\tpermutable_struct.append(sep_line)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tnonpermutable_struct.append(sep_line)\n",
        "\tstruct = permutable_struct + nonpermutable_struct\n",
        "\n",
        "\tNew_XYZ = open(starting_model, \"w\")\n",
        "\tNew_XYZ.write(str(len(struct)) + \"\\n\\n\")\n",
        "\tfor i in range(len(struct)):\n",
        "\t\tNew_XYZ.write(str(struct[i]).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\",\", \"\") + \"\\n\")\n",
        "\tNew_XYZ.close()\n",
        "\n",
        "\tNum_permutable_atoms = len(permutable_struct)\n",
        "\treturn Num_permutable_atoms\n",
        "\n",
        "def fitting(structure_catalogue, xyz, atom_ph, Qmin, Qmax, Qdamp, rmin, rmax, plot, index):\n",
        "    \"\"\"This function takes in a 'starting_model', and an 'index' from the 'structure_catalogue'. It generates the \n",
        "    corresponding structure and fit it to the 'Experimental_Data'.\"\"\"\n",
        "    \n",
        "    xyz_Mo = xyz[:NumMo].copy()\n",
        "    xyz_O = xyz[NumMo:len(xyz)].copy()\n",
        "    keep_O = np.zeros(len(xyz_O))\n",
        "    # Cycle through W atoms and delete W according to index 0's from permutation\n",
        "    delete_M = np.where(np.array(structure_catalogue)[index,:] == 0)[0]\n",
        "\n",
        "    # Delete atoms from starting model \n",
        "    xyz_Mo = np.delete(xyz_Mo, delete_M, 0)\n",
        "\n",
        "    # Cycle through all atoms that is not iteratable and test if it is within the threshold distance. Delete atoms with no bonds\n",
        "    for j in range(len(xyz_O)):\n",
        "        dists = np.sqrt((xyz_Mo[:,0]-xyz_O[j,0])**2+(xyz_Mo[:,1]-xyz_O[j,1])**2+(xyz_Mo[:,2]-xyz_O[j,2])**2)\n",
        "        if np.min(dists) < threshold:    \n",
        "            keep_O[j] = 1\n",
        "\n",
        "    # Cycle through W atoms and delete W according to index 0's from permutation\n",
        "    delete_O = np.where(np.array(keep_O) == 0)[0]\n",
        "    # Delete atoms from starting model \n",
        "    xyz_O = np.delete(xyz_O, delete_O, 0)\n",
        "\n",
        "    # Create structure for iterable (W) and non-iterable (O) atoms and combine them\n",
        "    Mo_cluster = Structure([Atom(atom_ph, xi) for xi in xyz_Mo])\n",
        "    O_cluster = Structure([Atom('O', xi) for xi in xyz_O])\n",
        "    cluster = Mo_cluster + O_cluster\n",
        "    \n",
        "    # Make a standard cluster refinement using Diffpy-CMI\n",
        "    # Import the data and make it a PDFprofile. Define the range of the data that will be used in the fit.\n",
        "    pdfprofile = Profile()\n",
        "    pdfparser = PDFParser()\n",
        "    pdfparser.parseFile(Experimental_Data)\n",
        "    pdfprofile.loadParsedData(pdfparser)\n",
        "    pdfprofile.setCalculationRange(xmin = rmin, xmax = rmax)\n",
        "\n",
        "    # Setup the PDFgenerator that calculates the PDF from the structure\n",
        "    pdfgenerator_cluster = PDFGenerator(\"G\")\n",
        "    # Add the profile and both generators to the PDFcontribution\n",
        "    pdfcontribution = FitContribution(\"pdf\")\n",
        "    pdfcontribution.setProfile(pdfprofile, xname=\"r\") \n",
        "    pdfcontribution.addProfileGenerator(pdfgenerator_cluster)\n",
        "    \n",
        "    pdfgenerator_cluster.setQmin(Qmin)\n",
        "    pdfgenerator_cluster.setQmax(Qmax)\n",
        "    pdfgenerator_cluster._calc.evaluatortype = 'OPTIMIZED'\n",
        "    pdfgenerator_cluster.setStructure(cluster, periodic = False)\n",
        "\n",
        "    # Use scaling factors proportional to molar content\n",
        "    pdfcontribution.setEquation('mc*G')\n",
        "\n",
        "    # Define the recipe to do the fit and add it to the PDFcontribution\n",
        "    recipe = FitRecipe()\n",
        "    recipe.addContribution(pdfcontribution)\n",
        "\n",
        "    # Avoid too much output during fitting \n",
        "    recipe.clearFitHooks()\n",
        "\n",
        "    # Add the scale factor.\n",
        "    recipe.addVar(pdfcontribution.mc, 1.0, tag = \"scale\")\n",
        "    \n",
        "    # Add the instrumental parameters to the two generators\n",
        "    pdfgenerator_cluster.qdamp.value = Qdamp\n",
        "    #pdfgenerator_cluster.qbroad.value = 0.00\n",
        "\n",
        "    # Add the delta2 parameters, and make sure it cannot take unphysical values\n",
        "    #recipe.addVar(pdfgenerator_cluster.delta2, 0, name = \"delta2_cluster\", tag = \"delta2\")\n",
        "    #recipe.restrain(\"delta2_cluster\", lb=0, ub = 7, sig=0.001);\n",
        "    \n",
        "    # Add ADP and \"cell\" for the cluster\n",
        "    phase_cluster = pdfgenerator_cluster.phase\n",
        "    atoms = phase_cluster.getScatterers()\n",
        "    lat = phase_cluster.getLattice()\n",
        "\n",
        "    recipe.newVar(\"zoomscale\", 1.0, tag = \"lat\")\n",
        "    recipe.constrain(lat.a, 'zoomscale')\n",
        "    recipe.constrain(lat.b, 'zoomscale')\n",
        "    recipe.constrain(lat.c, 'zoomscale')\n",
        "    recipe.restrain(\"zoomscale\", lb=0.95, ub = 1.05, sig=0.001)\n",
        "    \n",
        "    Mo_cluster = recipe.newVar(\"Mo_Biso_cluster\", 0.3, tag = 'adp_Mo')\n",
        "    O_cluster = recipe.newVar(\"O_Biso_cluster\", 0.4, tag = 'adp_O')\n",
        "\n",
        "    for atom in atoms:\n",
        "        if atom.element.title() == atom_ph:\n",
        "            recipe.constrain(atom.Biso, Mo_cluster)\n",
        "        elif atom.element.title() == \"O\":\n",
        "            recipe.constrain(atom.Biso, O_cluster)\n",
        "\n",
        "    recipe.restrain(\"Mo_Biso_cluster\", lb=0.08, ub = 3, sig=0.001)\n",
        "    recipe.restrain(\"O_Biso_cluster\", lb=0.08, ub = 3, sig=0.001)\n",
        "\n",
        "    pos_limit1 = 0.05\n",
        "    pos_limit2 = 0.02\n",
        "    pos_limit3 = 0.02\n",
        "\n",
        "    for atom in atoms:\n",
        "        if atom.element == atom_ph:\n",
        "            recipe.addVar(atom.x, name=atom.name+'_x1', tag='xyz1')\n",
        "            recipe.addVar(atom.y, name=atom.name+'_y1', tag='xyz1')\n",
        "            recipe.addVar(atom.z, name=atom.name+'_z1', tag='xyz1')       \n",
        "            #restrain atomic positions\n",
        "            lbx = atom.x.value-pos_limit1\n",
        "            ubx = atom.x.value+pos_limit1\n",
        "            recipe.restrain(atom.x, lb=lbx, ub = ubx, sig=0.001)\n",
        "            lby = atom.y.value-pos_limit1\n",
        "            uby = atom.y.value+pos_limit1\n",
        "            recipe.restrain(atom.y, lb=lby, ub = uby, sig=0.001)\n",
        "            lbz = atom.z.value-pos_limit1\n",
        "            ubz = atom.z.value+pos_limit1\n",
        "            recipe.restrain(atom.y, lb=lby, ub = uby, sig=0.001)\n",
        "\n",
        "    #free parameters are set\n",
        "    recipe.fix('all')\n",
        "    recipe.free(\"scale\")\n",
        "    leastsq(recipe.residual, recipe.getValues())\n",
        "    recipe.free(\"lat\")\n",
        "    leastsq(recipe.residual, recipe.getValues())\n",
        "    #recipe.free(\"adp_Mo\")\n",
        "    #leastsq(recipe.residual, recipe.getValues())\n",
        "    #recipe.free(\"adp_O\")\n",
        "    #leastsq(recipe.residual, recipe.getValues())\n",
        "    #recipe.free(\"xyz1\")\n",
        "    #leastsq(recipe.residual, recipe.getValues())\n",
        "    \n",
        "    # Turn off printout of iteration number.\n",
        "    #recipe.clearFitHooks()\n",
        "   \n",
        "    # We calculate the goodness-of-fit, Rwp\n",
        "    g = recipe.pdf.profile.y\n",
        "    gcalc = recipe.pdf.evaluate()\n",
        "    rfactor1 = np.sqrt(sum((g - gcalc)**2) / sum((g)**2))\n",
        "    \n",
        "    # if plot == 1 it will also plot the fit\n",
        "    if plot == 1:\n",
        "        print (\"FIT RESULTS\\n\")\n",
        "        res1 = FitResults(recipe)\n",
        "        print (res1)\n",
        "\n",
        "        # Plot the observed and refined PDF.\n",
        "        # Get the experimental data from the recipe\n",
        "        r = recipe.pdf.profile.x\n",
        "        gobs = recipe.pdf.profile.y\n",
        "\n",
        "        # Get the calculated PDF and compute the difference between the calculated and measured PDF\n",
        "        gcalc = recipe.pdf.evaluate()\n",
        "        baseline = 1.1 * gobs.min()\n",
        "        gdiff = gobs - gcalc\n",
        "\n",
        "        # Plot!\n",
        "        plt.figure()\n",
        "        plt.plot(r, gobs, 'bo', label=\"G(r) data\")\n",
        "        plt.plot(r, gcalc, 'r-', label=\"G(r) fit\")\n",
        "        plt.plot(r, gdiff + baseline, 'g-', label=\"G(r) diff\")\n",
        "        plt.plot(r, np.zeros_like(r) + baseline, 'k:')\n",
        "        plt.xlabel(r\"$r (\\AA)$\")\n",
        "        plt.ylabel(r\"$G (\\AA^{-2})$\")\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "    return 1-rfactor1\n",
        "\n",
        "def fitting_multiprocess(structure_catalogue, xyz, atom_ph, Qmin, Qmax, Qdamp, rmin, rmax, SaveName, cores=1):\n",
        "    \"\"\"This function runs the refinement of all the structures in the structure catalogue using multiprocessing\"\"\"\n",
        "    start_time = time.time()\n",
        "    values = []\n",
        "    # Set up multiprocessing refinement\n",
        "    fitindex = range(len(structure_catalogue))\n",
        "    p = Pool(processes=cores)\n",
        "    plot = 0\n",
        "    \n",
        "    func = partial(fitting, structure_catalogue, xyz, atom_ph, Qmin, Qmax, Qdamp, rmin, rmax, plot)\n",
        "    results = p.map(func, fitindex)\n",
        "    p.close()\n",
        "    p.join()\n",
        "    \n",
        "    # Start refinement and append results to lists\n",
        "    for i in fitindex:\n",
        "        if i % 100 == 0:\n",
        "            print (\"I have now fitted: \", str(i) + \" structures out of \" + str(len(structure_catalogue)))\n",
        "        rw = results[i]\n",
        "        values.append(rw)\n",
        "    values = np.reshape(values,(int(len(values)/1) , 1))\n",
        "    \n",
        "    # Save results in format that is suitable for Machine Learning\n",
        "    Result = np.column_stack([values, np.asarray(structure_catalogue)])\n",
        "    np.savetxt(SaveName, Result)\n",
        "    return Result\n",
        "\n",
        "def calculate_atomContributionValue(Result, saveResults):\n",
        "    \"\"\"Calculate atom contribution value list from the result array\"\"\"\n",
        "    \n",
        "    # Define AtomContributionValues vector\n",
        "    AtomContributionValues = Result[:,0]\n",
        "    \n",
        "    # Normalise the AtomContributionValues\n",
        "    amin, amax = min(AtomContributionValues), max(AtomContributionValues)\n",
        "    AtomContributionValues = (AtomContributionValues - amin) / (amax - amin)\n",
        "    AtomContributionValues_ph = AtomContributionValues.copy()\n",
        "    AtomContributionValues_ph.sort()\n",
        "\n",
        "    # Define colormap of viridis.reverse\n",
        "    norm = mpl.colors.Normalize(vmin=AtomContributionValues_ph[round((len(AtomContributionValues))/10)], vmax=AtomContributionValues_ph[-round((len(AtomContributionValues))/10)])\n",
        "    cmap = matplotlib.cm.cividis_r\n",
        "    m = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
        "    \n",
        "    # Save results to file\n",
        "    f = open(saveResults+\"AtomContributionValues_MotEx.txt\", \"w\")\n",
        "    f.write(\"\\nAtom contribution are calculated to: \\n\")\n",
        "    for i in range(len(AtomContributionValues)):\n",
        "        f.write(\"Atom # \"+ str(i+1) + \":  \"+ str(AtomContributionValues[i]) + \"  Colorcode:  \"+ mpl.colors.rgb2hex(m.to_rgba(AtomContributionValues[i]))+\"\\n\")\n",
        "    \n",
        "    return m, AtomContributionValues\n",
        "\n",
        "def Make_CrystalMakerFile(elements, xyz, AtomContributionValues, m, saveResults, threshold):\n",
        "    # Read bonds and colors of all atoms\n",
        "    bonding = []\n",
        "    with open(\"fast-MotEx/utils/Bonding.txt\", 'r') as fi:\n",
        "        for line in fi.readlines():\n",
        "            sep_line=line.strip('{}\\n\\r ').split()\n",
        "            bonding.append(sep_line)\n",
        "    bonding = np.array(bonding)\n",
        "    \n",
        "    # Output a crystalmaker file to visualize the results\n",
        "    CrystalMaker = open(saveResults + '_CrystalMaker.cmtx', 'w')\n",
        "\n",
        "    CrystalMaker.write(\"MOLE  CrystalMaker molecule format\\n\")\n",
        "    CrystalMaker.write(\"TITL  Molecule\\n\\n\")\n",
        "    CrystalMaker.write(\"! Model type\\n\")\n",
        "    CrystalMaker.write(\"MODL  1\\n\\n\")\n",
        "\n",
        "    CrystalMaker.write(\"! Depth fading settings\\n\")\n",
        "    CrystalMaker.write(\"DCUE  1.000000 0.212899 0.704686\\n\\n\")\n",
        "\n",
        "    CrystalMaker.write(\"! Colour definitions:\\n\")\n",
        "    CrystalMaker.write(\"TYPE\\n\")\n",
        "\n",
        "    # Assign colors to all the atoms\n",
        "    for iter, element in enumerate(elements):\n",
        "        if iter < NumW:\n",
        "            #CrystalMaker.write(element + str(iter+1) + \" 1.32 \")\n",
        "            CrystalMaker.write(element + str(iter+1) + \" \" + bonding[np.where(bonding == element)[0][0], 1] + \" \")\n",
        "            rgb1 = m.to_rgba(AtomContributionValues[iter])[:-1][0]\n",
        "            rgb2 = m.to_rgba(AtomContributionValues[iter])[:-1][1]\n",
        "            rgb3 = m.to_rgba(AtomContributionValues[iter])[:-1][2]\n",
        "            CrystalMaker.write(str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3))\n",
        "            CrystalMaker.write(\"\\n\")\n",
        "        else:\n",
        "            #CrystalMaker.write(element + str(iter+1) + \" 0.66 \")\n",
        "            CrystalMaker.write(element + str(iter+1) + \" \" + bonding[np.where(bonding == element)[0][0], 1] + \" \")\n",
        "            rgb1 = int(float(bonding[np.where(bonding == element)[0][0], 2])*255) #mpl.colors.to_rgb(\"#FF0000\")[0]\n",
        "            rgb2 = int(float(bonding[np.where(bonding == element)[0][0], 3])*255) #mpl.colors.to_rgb(\"#FF0000\")[1]\n",
        "            rgb3 = int(float(bonding[np.where(bonding == element)[0][0], 4])*255) #mpl.colors.to_rgb(\"#FF0000\")[2]\n",
        "            CrystalMaker.write(str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3))\n",
        "            CrystalMaker.write(\"\\n\")\n",
        "    \n",
        "    CrystalMaker.write(\"\\n\")\n",
        "    CrystalMaker.write(\"! Atoms list\\n\")\n",
        "    CrystalMaker.write(\"! Bond Specifications\\n\")\n",
        "    \n",
        "    # Assign bonds between the atoms\n",
        "    for iter, element in enumerate(elements):\n",
        "        if iter < NumW:\n",
        "            NI_elements = np.delete(np.unique(elements), np.where(np.unique(elements) == element)[0])\n",
        "            for NI_element in NI_elements:\n",
        "                CrystalMaker.write(\"BMAX \" + element + \" \" + str(NI_element) + \"  \" + str(threshold))\n",
        "                CrystalMaker.write(\"\\n\")\n",
        "    \n",
        "    CrystalMaker.write(\"\\n\")\n",
        "    CrystalMaker.write(\"! Atoms list\\n\")\n",
        "    CrystalMaker.write(\"ATOM\\n\")\n",
        "    \n",
        "    # Assign coordinates to the atoms\n",
        "    for iter, element in enumerate(elements):\n",
        "        if iter < NumW:\n",
        "            CrystalMaker.write(element + \" \" + element + str(iter+1) + \" \" + str(xyz[iter][0]) + \" \" + str(xyz[iter][1]) + \" \" + str(xyz[iter][2]) + \"\\n\")\n",
        "        else:\n",
        "            CrystalMaker.write(element + \" \" + element + str(iter+1) + \" \" + str(xyz[iter][0]) + \" \" + str(xyz[iter][1]) + \" \" + str(xyz[iter][2]) + \"\\n\")\n",
        "\n",
        "    CrystalMaker.close()\n",
        "    \n",
        "    return None\n",
        "\n",
        "def Make_VestaFile(elements, xyz, AtomContributionValues, m, saveResults, threshold):\n",
        "    # Read bonds and colors of all atoms\n",
        "    bonding = []\n",
        "    with open(\"fast-MotEx/utils/Bonding.txt\", 'r') as fi:\n",
        "        for line in fi.readlines():\n",
        "            sep_line=line.strip('{}\\n\\r ').split()\n",
        "            bonding.append(sep_line)\n",
        "    bonding = np.array(bonding)\n",
        "\n",
        "    # Output a Vesta file to visualize the results\n",
        "    Vesta = open(saveResults + '_Vesta.vesta', 'w')\n",
        "\n",
        "    Vesta.write(\"#VESTA_FORMAT_VERSION 3.5.4\\n\\n\\n\")\n",
        "    Vesta.write(\"MOLECULE\\n\\n\")\n",
        "    Vesta.write(\"Title\\n\")\n",
        "    Vesta.write(\"XYZ file\\n\\n\")\n",
        "\n",
        "    Vesta.write(\"STRUC\\n\")\n",
        "    # Assign coordinates to the atoms\n",
        "    for iter, element in enumerate(elements):\n",
        "        Vesta.write(str(iter+1) + \" \" + element + \" \" + element + str(iter+1) + \" 1.0000 \" + str(xyz[iter][0]) + \" \" + str(xyz[iter][1]) + \" \" + str(xyz[iter][2]) + \"1\" + \" -\" + \"\\n\")\n",
        "        Vesta.write(\"0 0 0 0\\n\")\n",
        "    Vesta.write(\"  0 0 0 0 0 0 0\\n\")\n",
        "\n",
        "    Vesta.write(\"SBOND\\n\")\n",
        "    # Assign bonds between the atoms\n",
        "    unique_elements = np.unique(elements)\n",
        "    for iter, element1 in enumerate(unique_elements):\n",
        "      for iter, element2 in enumerate(unique_elements):\n",
        "        if not element1 == element2:\n",
        "          Vesta.write(str(iter+1) + \" \" + element1 + \" \" + element2 + \" 0.0 \" + str(threshold) + \" 0 1 1 0 1 0.25 2 127 127 127\\n\")\n",
        "          Vesta.write(\"0 0 0 0\\n\")\n",
        "    \n",
        "    Vesta.write(\"SITET\\n\")\n",
        "    # Assign colors to all the atoms\n",
        "    for iter, element in enumerate(elements):\n",
        "        if iter < NumW:\n",
        "            rgb1 = int(m.to_rgba(AtomContributionValues[iter])[:-1][0]*255)\n",
        "            rgb2 = int(m.to_rgba(AtomContributionValues[iter])[:-1][1]*255)\n",
        "            rgb3 = int(m.to_rgba(AtomContributionValues[iter])[:-1][2]*255)\n",
        "            Vesta.write(str(iter+1) + \" \" + element + str(iter+1) + \" \" + bonding[np.where(bonding == element)[0][0], 1] + \" \" + str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3) + \" \" + str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3) + \" 204 0\\n\")\n",
        "        else:\n",
        "            rgb1 = int(float(bonding[np.where(bonding == element)[0][0], 2])*255)\n",
        "            rgb2 = int(float(bonding[np.where(bonding == element)[0][0], 3])*255)\n",
        "            rgb3 = int(float(bonding[np.where(bonding == element)[0][0], 4])*255)\n",
        "            Vesta.write(str(iter+1) + \" \" + element + str(iter+1) + \" \" + bonding[np.where(bonding == element)[0][0], 1] + \" \" + str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3) + \" \" + str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3) + \" 204 0\\n\")\n",
        "    Vesta.write(\"0 0 0 0 0 0\\n\")\n",
        "    \n",
        "    Vesta.write(\"ATOMT\\n\")\n",
        "    done_deal_atoms = []\n",
        "    for iter, element in enumerate(elements):\n",
        "      if element not in done_deal_atoms:\n",
        "        rgb1 = int(float(bonding[np.where(bonding == element)[0][0], 2])*255)\n",
        "        rgb2 = int(float(bonding[np.where(bonding == element)[0][0], 3])*255)\n",
        "        rgb3 = int(float(bonding[np.where(bonding == element)[0][0], 4])*255)\n",
        "        Vesta.write(str(iter+1) + \" \" + element + \" \" + bonding[np.where(bonding == element)[0][0], 1] + \" \" + str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3) + \" \" + str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3) + \" 204\\n\")\n",
        "        done_deal_atoms.append(element)\n",
        "    Vesta.write(\"0 0 0 0 0 0\\n\")\n",
        "\n",
        "    Vesta.close()\n",
        "    \n",
        "    return None\n"
      ],
      "metadata": {
        "id": "ZTph_lVGc0r5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define variables"
      ],
      "metadata": {
        "id": "kYI192OwiNwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "starting_model = list(files.upload())[0] # Name of the starting model file\n",
        "StemName = list(files.upload())[0][:-3] # Upload PDF(s) from local computer\n",
        "threshold = 2.6 # Longest bond distance between the metal and oxygen atom\n",
        "allowed_atoms = [\"W\"] # The atoms that should be permuted, can be multiple atoms\n",
        "atom_ph, Qmin, Qmax, Qdamp, rmin, rmax = \"W\", 0.7, 20, 0.05, 1.6, 10\n",
        "#atom_ph, Qmin, Qmax, Qdamp, rmin, rmax = \"Mo\", 0.5, 24, 0.04, 3, 12\n"
      ],
      "metadata": {
        "id": "ZZDnsIkpiLIV",
        "outputId": "01254e7f-ddad-45c4-c6bf-4c13ffdf76b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a21666cd631d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstarting_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Name of the starting model file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mStemName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Upload PDF(s) from local computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.6\u001b[0m \u001b[0;31m# Longest bond distance between the metal and oxygen atom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mallowed_atoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# The atoms that should be permuted, can be multiple atoms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0matom_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQdamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"W\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "Kz4pl8PZiQKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saveResults = \"./\"\n",
        "start_time = time.time()\n",
        "\n",
        "# Step 1: Make the structure catalogue\n",
        "NumMo = format_XYZ(starting_model, allowed_atoms) # Format the starting model and calculate then number of atoms that should be permuted in the starting model\n",
        "structure_catalogue = structure_catalogue_maker(Number_of_atoms=NumMo)\n",
        "print (\"Catalogue maker: \", time.time() - start_time)\n",
        "\n",
        "# Step 2: Fit all of the structures from the catalogue of structure motifs to the dataset\n",
        "### First define the experimental data path and the path you want the structure catalogue with fits to be saved\n",
        "Experimental_Data = StemName+\".gr\" # Name of the experimental file\n",
        "saveFits = StemName+\".txt\" # Name of the saved fits file\n",
        "\n",
        "# Load data and start model\n",
        "Exp_r, Exp_Gr, elements, xyz = Load(Experimental_Data, starting_model)\n",
        "print (\"Data loader: \", time.time() - start_time)\n",
        "\n",
        "### Produce organized structure catalogue with Rwp values\n",
        "Result = fitting_multiprocess(structure_catalogue, xyz, atom_ph, Qmin, Qmax, Qdamp, rmin, rmax, SaveName=saveFits, cores=None)\n",
        "print (\"Getting results: \", time.time() - start_time)\n",
        "\n",
        "# Step 4: Calculate Atom Contribution values\n",
        "m, AtomContributionValues = calculate_atomContributionValue(Result, saveResults)\n",
        "print (\"Calculating atom contribution values: \", time.time() - start_time)\n",
        "\n",
        "Make_CrystalMakerFile(elements, xyz, AtomContributionValues, m, StemName, threshold)\n",
        "Make_VestaFile(elements, xyz, AtomContributionValues, m, StemName, threshold)\n",
        "print (\"Output a CrystalMaker file: \", time.time() - start_time)\n",
        "\n",
        "print (time.time() - start_time, \" s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La5rMFNsiQVx",
        "outputId": "3a17ac4d-9d3b-4510-884f-9bf732faf172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catalogue maker:  0.006275653839111328\n",
            "Data loader:  0.37058568000793457\n",
            "I have now fitted:  0 structures out of 24\n",
            "Getting results:  9.955245733261108\n",
            "Calculating atom contribution values:  9.963000059127808\n",
            "Output a CrystalMaker file:  10.002787351608276\n",
            "10.003013372421265  s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download results"
      ],
      "metadata": {
        "id": "4Hi1V86wjcgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the latest results\n",
        "files.download(StemName + '_CrystalMaker.cmtx')\n",
        "files.download(StemName + '_Vesta.vesta')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7LHJ3nXRiTcs",
        "outputId": "64cccf77-3d17-47cd-8a3f-059d3227ebbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa9378bd-e076-48ba-8882-70c24a24aa09\", \"DanMAX_AlphaKeggin_nyquist_CrystalMaker.cmtx\", 6305)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7340c8e-9fcc-4832-afa5-1017f2068ee4\", \"DanMAX_AlphaKeggin_nyquist_Vesta.vesta\", 9671)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XXWPYNQoBRe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}