{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Welcome to MotEx </center></h1>\n",
    "\n",
    "\n",
    "\n",
    "# First import modules, set seed parameters and import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formfactor_dict = {\n",
    "  \"H\": 1, \"He\": 2, \"Li\": 3, \"Be\": 4, \"B\": 5, \"C\": 6, \"N\": 7, \"O\": 8, \"F\": 9, \"Ne\": 10, \"Na\": 11, \"Mg\": 12,\n",
    "  \"Al\": 13, \"Si\": 14, \"P\": 15, \"S\": 16, \"Cl\": 17, \"Ar\": 18, \"K\": 19, \"Ca\": 20, \"Sc\": 21, \"Ti\": 22, \"V\": 23, \"Cr\": 24,\n",
    "  \"Mn\": 25, \"Fe\": 26, \"Co\": 27, \"Ni\": 28, \"Cu\": 29, \"Zn\": 30, \"Ga\": 31, \"Ge\": 32, \"As\": 33, \"Se\": 34, \"Br\": 35, \"Kr\": 36,\n",
    "  \"Rb\": 37, \"Sr\": 38, \"Y\": 39, \"Zr\": 40, \"Nb\": 41, \"Mo\": 42, \"Tc\": 43, \"Ru\": 44, \"Rh\": 45, \"Pd\": 46, \"Ag\": 47, \"Cd\": 48,\n",
    "  \"In\": 49, \"Sn\": 50, \"Sb\": 51, \"Te\": 52, \"I\": 53, \"Xe\": 54, \"Cs\": 55, \"Ba\": 56, \"Hf\": 72, \"Ta\": 73, \"W\": 74, \"Re\": 75,\n",
    "  \"Os\": 76, \"Ir\": 77, \"Pt\": 78, \"Au\": 79, \"Hg\": 80, \"Tl\": 81, \"Pb\": 82, \"Bi\": 83, \"Po\": 84, \"At\": 85, \"Rn\": 86, \"Fr\": 87,\n",
    "  \"Ra\": 88, \"Rf\": 104, \"Db\": 105, \"Sg\": 106, \"Bh\": 107, \"Hs\": 108, \"Mt\": 109, \"Ds\": 110, \"Rg\": 111, \"Cn\": 112, \"Nh\": 113, \"Fl\": 114,\n",
    "  \"Mc\": 115, \"Lv\": 116, \"Ts\": 117, \"Og\": 118, \"La\": 57, \"Ce\": 58, \"Pr\": 59, \"Nd\": 60, \"Pm\": 61, \"Sm\": 62, \"Eu\": 63, \"Gd\": 64,\n",
    "  \"Tb\": 65, \"Dy\": 66, \"Ho\": 67, \"Er\": 68, \"Tm\": 69, \"Yb\": 70, \"Lu\": 71, \"Ac\": 89, \"Th\": 90, \"Pa\": 91, \"U\": 92, \"Np\": 93,\n",
    "  \"Pu\": 94, \"Am\": 95, \"Cm\": 96, \"Bk\": 97, \"Cf\": 98, \"Es\": 99, \"Fm\": 100, \"Md\": 101, \"No\": 102, \"Lr\": 103, \"D\": 1}\n",
    "\n",
    "def Load_startModel(starting_model):\n",
    "    \"\"\"This function loads the starting model structure\"\"\"\n",
    "\n",
    "    # Read structure and divide it into two lists: Atoms we want to iterate (W) and atoms we do not iterate (O)\n",
    "    struct=[]\n",
    "    with open(starting_model, 'r') as fi:\n",
    "        for line in fi.readlines():\n",
    "            sep_line=line.strip('{}\\n\\r ').split()\n",
    "            if len(sep_line)==4: #  tillader andre informationer i xyz filen some ikke skal laeses\n",
    "                struct.append(sep_line)\n",
    "    elements=np.array(struct)[:,0]\n",
    "    xyz=(np.array(struct)[:,1:].astype(float))\n",
    "    \n",
    "    return elements, xyz\n",
    "\n",
    "def fitting(Experimental_Data, structure_catalogue, formfactor_dict, elements, xyz, frame):    \n",
    "    \"\"\"This function takes in a 'starting_model', and an 'index' from the 'structure_catalogue'. It generates the \n",
    "    corresponding structure and calculate the Rwp value to the 'Experimental_Data without fitting\"\"\"\n",
    "    \n",
    "    # Get experimental data\n",
    "    for skip_row in range(100):\n",
    "        try:\n",
    "            Exp_data = np.loadtxt(Experimental_Data + \"_\" + str(frame) +\".gr\", skiprows=skip_row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    # Nyquist sampling the data by only using every 10nth datapoint\n",
    "    if Exp_data[1,0] - Exp_data[0,0] < 0.1:\n",
    "        Exp_r, Exp_Gr = Exp_data[::10,0], Exp_data[::10,1]\n",
    "    else:\n",
    "        Exp_r, Exp_Gr = Exp_data[:,0], Exp_data[:,1]\n",
    "    # Normalise data\n",
    "    Exp_Gr /= max(Exp_Gr)\n",
    "    \n",
    "    \n",
    "    Rwps = []\n",
    "    for index in range(len(structure_catalogue)):\n",
    "        # Cycle through W atoms and delete W according to index 0's from permutation\n",
    "        delete_M = np.where(np.array(structure_catalogue)[index,:] == 0)[0]\n",
    "\n",
    "        # Delete atoms from starting model \n",
    "        elements_ph = np.delete(elements, delete_M, 0)\n",
    "        xyz_ph = np.delete(xyz, delete_M, 0)\n",
    "        elements_ph = [int(formfactor_dict[element]) for element in elements_ph]\n",
    "        \n",
    "        # Calculate distances and formfactor to simulate PDF\n",
    "        i, j = np.triu_indices(len(xyz_ph), k=1)\n",
    "        dists = np.sqrt((xyz_ph[i,0]-xyz_ph[j,0])**2+(xyz_ph[i,1]-xyz_ph[j,1])**2+(xyz_ph[i,2]-xyz_ph[j,2])**2)\n",
    "        formfactor = np.array(elements_ph)[i] * np.array(elements_ph)[j]\n",
    "        \n",
    "        # Simulate PDF\n",
    "        #Sim_Gr, Sim_r = torch.histogram(torch.tensor(dists).float(), bins=301, range=[-0.05,30.05], weight=torch.tensor(formfactor).float())\n",
    "        Sim_Gr, Sim_r = np.histogram(np.array(dists, dtype=float), bins=len(Exp_r), range=[Exp_r[0]-0.05,Exp_r[-1]+0.05], weights=np.array(formfactor, dtype=float))\n",
    "        Sim_r = (Sim_r[1:] + Sim_r[:-1]) / 2\n",
    "\n",
    "        # Normalise PDF\n",
    "        Sim_Gr /= Exp_r\n",
    "        Sim_Gr = np.nan_to_num(Sim_Gr, 0)\n",
    "        Sim_Gr /= np.max(Sim_Gr)\n",
    "\n",
    "        # Calculate Rwp value\n",
    "        Rwp = np.sqrt(sum((Exp_Gr - Sim_Gr)**2) / sum((Exp_Gr)**2))\n",
    "        # Save to Result array\n",
    "        Rwps.append(Rwp)\n",
    "        \n",
    "    return Rwps\n",
    "\n",
    "def fitting_multiprocess(Experimental_Data, frames, structure_catalogue, formfactor_dict, elements, xyz, saveFits, cores=None):\n",
    "    \"\"\"This function runs the calculations of all the frames using multiprocessing\"\"\"\n",
    "    \n",
    "    # Set up multiprocessing refinement\n",
    "    fitindex = range(frames)\n",
    "    p = Pool(processes=cores)\n",
    "    func = partial(fitting, Experimental_Data, structure_catalogue, formfactor_dict, elements, xyz)\n",
    "    results = p.map(func, fitindex)\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "    # Start calculating residuals and append results to lists\n",
    "    Result_all = []\n",
    "    for frame in fitindex:\n",
    "        Rwps = results[frame]\n",
    "        Result = np.column_stack([Rwps, np.asarray(structure_catalogue)])\n",
    "        Result_all.append(Result)\n",
    "        np.savetxt(saveFits + \"_\" + str(frame) + \".txt\", Result)\n",
    "    \n",
    "    return Result_all\n",
    "\n",
    "def structure_catalogue_maker(Number_of_atoms):\n",
    "    \"\"\"Makes a catalogue of structures\"\"\"\n",
    "    \n",
    "    structure_catalogue = np.ones((Number_of_atoms,Number_of_atoms))\n",
    "    structure_catalogue[np.array([range(Number_of_atoms)]),np.array([range(Number_of_atoms)])] = 0\n",
    "    return structure_catalogue\n",
    "\n",
    "def calculate_atomContributionValue(Result, min_norm, max_norm, saveResults, id_number):\n",
    "    \"\"\"Calculate atom contribution value list from the result array\"\"\"\n",
    "    \n",
    "    # Define AtomContributionValues vector\n",
    "    AtomContributionValues = Result[:,0]\n",
    "    \n",
    "    # Normalise the AtomContributionValues\n",
    "    AtomContributionValues = (AtomContributionValues - min_norm) / (max_norm - min_norm)\n",
    "    \n",
    "    # Define colormap of viridis.reverse\n",
    "    norm = mpl.colors.Normalize(vmin=min(AtomContributionValues), vmax=max(AtomContributionValues))\n",
    "    cmap = matplotlib.cm.cividis_r\n",
    "    m = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    \n",
    "    # Save results to file\n",
    "    f = open(saveResults+\"AtomContributionValues\"+str(id_number)+\".txt\", \"w\")\n",
    "    f.write(\"\\nAtom contribution are calculated to: \\n\")\n",
    "    for i in range(len(AtomContributionValues)):\n",
    "        f.write(\"Atom # \"+ str(i+1) + \":  \"+ str(AtomContributionValues[i]) + \"  Colorcode:  \"+ mpl.colors.rgb2hex(m.to_rgba(AtomContributionValues[i]))+\"\\n\")\n",
    "    \n",
    "    return m, AtomContributionValues\n",
    "\n",
    "def Make_CrystalMakerFile(elements, xyz, AtomContributionValues, m, saveResults, id_number):\n",
    "    \"\"\"Make a crystalmaker file were the atoms are colored after their atom contribution value\"\"\"\n",
    "    \n",
    "    # Output a crystalmaker file to visualize the results\n",
    "    CrystalMaker = open(saveResults+'CrystalMaker'+str(id_number)+'.cmtx', 'w')\n",
    "\n",
    "    CrystalMaker.write(\"MOLE  CrystalMaker molecule format\\n\")\n",
    "    CrystalMaker.write(\"TITL  Molecule\\n\\n\")\n",
    "    CrystalMaker.write(\"! Model type\\n\")\n",
    "    CrystalMaker.write(\"MODL  1\\n\\n\")\n",
    "\n",
    "    CrystalMaker.write(\"! Depth fading settings\\n\")\n",
    "    CrystalMaker.write(\"DCUE  1.000000 0.212899 0.704686\\n\\n\")\n",
    "\n",
    "    CrystalMaker.write(\"! Colour definitions:\\n\")\n",
    "    CrystalMaker.write(\"TYPE\\n\")\n",
    "\n",
    "    # Assign colors to all the atoms\n",
    "    for iter, element in enumerate(elements):\n",
    "        if iter < NumW:\n",
    "            CrystalMaker.write(element + str(iter+1) + \" 1.32 \")\n",
    "            rgb1 = m.to_rgba(AtomContributionValues[iter])[:-1][0]\n",
    "            rgb2 = m.to_rgba(AtomContributionValues[iter])[:-1][1]\n",
    "            rgb3 = m.to_rgba(AtomContributionValues[iter])[:-1][2]\n",
    "            CrystalMaker.write(str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3))\n",
    "            CrystalMaker.write(\"\\n\")\n",
    "        else:\n",
    "            CrystalMaker.write(element + str(iter+1) + \" 0.66 \")\n",
    "            rgb1 = mpl.colors.to_rgb(\"#FF0000\")[0]\n",
    "            rgb2 = mpl.colors.to_rgb(\"#FF0000\")[1]\n",
    "            rgb3 = mpl.colors.to_rgb(\"#FF0000\")[2]\n",
    "            CrystalMaker.write(str(rgb1) + \" \" + str(rgb2) + \" \" + str(rgb3))\n",
    "            CrystalMaker.write(\"\\n\")\n",
    "    \n",
    "    CrystalMaker.write(\"\\n\")\n",
    "    CrystalMaker.write(\"! Atoms list\\n\")\n",
    "    CrystalMaker.write(\"! Bond Specifications\\n\")\n",
    "    \n",
    "    # Assign bonds between the atoms\n",
    "    for iter, element in enumerate(elements[:NumW]):\n",
    "        if iter < NumW:\n",
    "            NI_elements = np.delete(np.unique(elements), np.where(np.unique(elements) == element)[0])\n",
    "            for NI_element in NI_elements:\n",
    "                CrystalMaker.write(\"BMAX \" + element + str(iter+1) + \" \" + str(NI_element) + \"  2.6\")#    \" O  2.6\")\n",
    "                CrystalMaker.write(\"\\n\")\n",
    "    \n",
    "    CrystalMaker.write(\"\\n\")\n",
    "    CrystalMaker.write(\"! Atoms list\\n\")\n",
    "    CrystalMaker.write(\"ATOM\\n\")\n",
    "    \n",
    "    # Assign coordinates to the atoms\n",
    "    for iter, element in enumerate(elements):\n",
    "        if iter < NumW:\n",
    "            CrystalMaker.write(element + str(iter+1) + \" \" + element + str(iter+1) + \" \" + str(xyz[iter][0]) + \" \" + str(xyz[iter][1]) + \" \" + str(xyz[iter][2]) + \"\\n\")\n",
    "        else:\n",
    "            CrystalMaker.write(element + \" \" + element + str(iter+1) + \" \" + str(xyz[iter][0]) + \" \" + str(xyz[iter][1]) + \" \" + str(xyz[iter][2]) + \"\\n\")\n",
    "\n",
    "    CrystalMaker.close()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to vectorize over the number of atoms - never worked because could not vectorize the histogram making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame:  0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "(200, 103285)\n",
      "(200, 103285)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-40f3c5823f57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mSim_Gr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExp_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mbin_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mExp_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExp_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mSim_Gr_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSim_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogramdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExp_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbin_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \"\"\"\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogramdd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogramdd\u001b[0;34m(sample, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# Compute the number of repetitions in xy and assign it to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0;31m# flattened histmat.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;31m# Shape into a proper matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "frame = 0\n",
    "print (\"frame: \", frame)\n",
    "### First define the experimental data path and the path you want the structure catalogue with fits to be saved\n",
    "Experimental_Data = \"Experimental_Data/\"+StemName+\"_\"+str(frame)+\".gr\" # Name of the experimental file\n",
    "saveFits = \"Training_Data/\"+StemName+str(frame)+\".txt\" # Name of the saved fits file\n",
    "# Load data and start model\n",
    "Exp_r, Exp_Gr, elements, xyz = Load(Experimental_Data, starting_model)\n",
    "print (\"1\")\n",
    "\n",
    "# Step 1: Make the structure catalogue\n",
    "structure_catalogue = structure_catalogue_maker(Number_of_atoms=NumW)\n",
    "Exp_r, Exp_Gr, elements, xyz = Load(Experimental_Data, starting_model)\n",
    "xyz = np.repeat(xyz.reshape(1, -1, 3), repeats=200, axis=0)\n",
    "elements = np.array([int(formfactor_dict[element]) for element in elements])\n",
    "elements = np.repeat(elements.reshape(1,-1), repeats=200, axis=0)\n",
    "print (\"2\")\n",
    "\n",
    "# Make elements catalogue\n",
    "elements_iterable = elements[:,:NumW]\n",
    "elements_noniterable = elements[:,NumW:]\n",
    "elements_iterable = elements_iterable[~np.eye(elements_iterable.shape[0],dtype=bool)].reshape(elements_iterable.shape[0],-1)\n",
    "elements = np.concatenate((elements_iterable, elements_noniterable), axis=1)\n",
    "print (\"3\")\n",
    "\n",
    "# Make xyz catalogue\n",
    "xyz_iterable = xyz[:,:NumW, :]\n",
    "xyz_noniterable = xyz[:,NumW:, :]\n",
    "xyz_iterable = xyz_iterable[~np.eye(xyz_iterable.shape[0],dtype=bool)].reshape(xyz_iterable.shape[0],-1, 3)\n",
    "xyz = np.concatenate((xyz_iterable, xyz_noniterable), axis=1)\n",
    "print (\"4\")\n",
    "\n",
    "# Calculate distances and formfactor to simulate PDF\n",
    "i, j = np.triu_indices(np.shape(xyz)[1], k=1)\n",
    "dists = np.sqrt((xyz[:,i,0]-xyz[:,j,0])**2+(xyz[:,i,1]-xyz[:,j,1])**2+(xyz[:,i,2]-xyz[:,j,2])**2)\n",
    "formfactor = elements[:,i] * elements[:,j]\n",
    "print (\"5\")\n",
    "print (np.shape(dists))\n",
    "print (np.shape(formfactor))\n",
    "\n",
    "# Simulate PDF\n",
    "#Sim_Gr, Sim_r = torch.histogram(torch.tensor(dists).float(), bins=301, range=[-0.05,30.05], weight=torch.tensor(formfactor).float())\n",
    "\n",
    "bin_range = np.array([Exp_r[0]-0.05, Exp_r[-1]+0.05]).reshape(1, -1).repeat(2, axis=0)\n",
    "Sim_Gr_ph, Sim_r = np.histogramdd(dists[:2].T, bins=len(Exp_r), range=bin_range, weights=np.array(formfactor, dtype=float)[:22].T)\n",
    "\n",
    "\"\"\"\n",
    "Sim_Gr = np.zeros((len(dists), len(Exp_r)))\n",
    "for i in range(len(dists)):\n",
    "    Sim_Gr_ph, Sim_r = np.histogram(dists[i], bins=len(Exp_r), range=[Exp_r[0]-0.05, Exp_r[-1]+0.05], weights=np.array(formfactor[i], dtype=float))\n",
    "    # Normalise PDF\n",
    "    Sim_Gr_ph /= Exp_r\n",
    "    Sim_Gr_ph = np.nan_to_num(Sim_Gr_ph, 0)\n",
    "    Sim_Gr_ph /= np.max(Sim_Gr_ph)\n",
    "    Sim_Gr[i] = Sim_Gr_ph\n",
    "Sim_r = (Sim_r[1:] + Sim_r[:-1]) / 2\n",
    "\n",
    "# Calculate Rwp value\n",
    "Exp_Gr = np.repeat(Exp_Gr.reshape(1, -1), repeats=200, axis=0)\n",
    "Rwp = np.sqrt(np.sum((Exp_Gr - Sim_Gr)**2, axis=1) / np.sum(((Exp_Gr)**2), axis=1))\n",
    "\n",
    "print (time.time() - start_time, \" s\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(structure_catalogue, formfactor_dict, Exp_r, Exp_Gr, elements, xyz, SaveName):    \n",
    "    \"\"\"This function takes in a 'starting_model', and an 'index' from the 'structure_catalogue'. It generates the \n",
    "    corresponding structure and calculate the Rwp value to the 'Experimental_Data without fitting\"\"\"\n",
    "    \n",
    "    # Step 1: Make the structure catalogue\n",
    "    structure_catalogue = structure_catalogue_maker(Number_of_atoms=NumW)\n",
    "    Exp_r, Exp_Gr, elements, xyz = Load(Experimental_Data, starting_model)\n",
    "    xyz = np.repeat(xyz.reshape(1, -1, 3), repeats=200, axis=0)\n",
    "    elements = np.array([int(formfactor_dict[element]) for element in elements])\n",
    "    elements = np.repeat(elements.reshape(1,-1), repeats=200, axis=0)\n",
    "\n",
    "    # Make elements catalogue\n",
    "    elements_iterable = elements[:,:NumW]\n",
    "    elements_noniterable = elements[:,NumW:]\n",
    "    elements_iterable = elements_iterable[~np.eye(elements_iterable.shape[0],dtype=bool)].reshape(elements_iterable.shape[0],-1)\n",
    "    elements = np.concatenate((elements_iterable, elements_noniterable), axis=1)\n",
    "    \n",
    "    # Make xyz catalogue\n",
    "    xyz_iterable = xyz[:,:NumW, :]\n",
    "    xyz_noniterable = xyz[:,NumW:, :]\n",
    "    xyz_iterable = xyz_iterable[~np.eye(xyz_iterable.shape[0],dtype=bool)].reshape(xyz_iterable.shape[0],-1, 3)\n",
    "    xyz = np.concatenate((xyz_iterable, xyz_noniterable), axis=1)\n",
    "    \n",
    "    # Calculate distances and formfactor to simulate PDF\n",
    "    i, j = np.triu_indices(np.shape(xyz)[1], k=1)\n",
    "    dists = np.sqrt((xyz[:,i,0]-xyz[:,j,0])**2+(xyz[:,i,1]-xyz[:,j,1])**2+(xyz[:,i,2]-xyz[:,j,2])**2)\n",
    "    formfactor = elements[:,i] * elements[:,j]\n",
    "\n",
    "    # Simulate PDF\n",
    "    #Sim_Gr, Sim_r = torch.histogram(torch.tensor(dists).float(), bins=301, range=[-0.05,30.05], weight=torch.tensor(formfactor).float())\n",
    "    Sim_Gr = np.zeros((len(dists), len(Exp_r)))\n",
    "    for i in range(len(dists)):\n",
    "        Sim_Gr_ph, Sim_r = np.histogram(dists[i], bins=len(Exp_r), range=[Exp_r[0]-0.05, Exp_r[-1]+0.05], weights=np.array(formfactor[i], dtype=float))\n",
    "        # Normalise PDF\n",
    "        Sim_Gr_ph /= Exp_r\n",
    "        Sim_Gr_ph = np.nan_to_num(Sim_Gr_ph, 0)\n",
    "        Sim_Gr_ph /= np.max(Sim_Gr_ph)\n",
    "        Sim_Gr[i] = Sim_Gr_ph\n",
    "    Sim_r = (Sim_r[1:] + Sim_r[:-1]) / 2\n",
    "\n",
    "    # Calculate Rwp value\n",
    "    Exp_Gr = np.repeat(Exp_Gr.reshape(1, -1), repeats=200, axis=0)\n",
    "    Rwp = np.sqrt(np.sum((Exp_Gr - Sim_Gr)**2, axis=1) / np.sum(((Exp_Gr)**2), axis=1))\n",
    "    \n",
    "    Result = np.column_stack([Rwp, np.asarray(structure_catalogue)])\n",
    "    np.savetxt(SaveName, Result)\n",
    "    \n",
    "    return Result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame:  0\n",
      "frame:  1\n",
      "frame:  2\n",
      "frame:  3\n",
      "frame:  4\n",
      "frame:  5\n",
      "frame:  6\n",
      "frame:  7\n",
      "frame:  8\n",
      "frame:  9\n",
      "63.01496911048889\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Step 1: Make the structure catalogue\n",
    "structure_catalogue = structure_catalogue_maker(Number_of_atoms=NumW)\n",
    "\n",
    "Result_list = np.zeros((frames, NumW, NumW+1))\n",
    "for frame in range(frames):\n",
    "    print (\"frame: \", frame)\n",
    "    ### First define the experimental data path and the path you want the structure catalogue with fits to be saved\n",
    "    Experimental_Data = \"Experimental_Data/\"+StemName+\"_\"+str(frame)+\".gr\" # Name of the experimental file\n",
    "    saveFits = \"Training_Data/\"+StemName+str(frame)+\".txt\" # Name of the saved fits file\n",
    "    # Load data and start model\n",
    "    Exp_r, Exp_Gr, elements, xyz = Load(Experimental_Data, starting_model)\n",
    "    \n",
    "    ### Step 2: Produce organized structure catalogue with Rwp values\n",
    "    Result = fitting(structure_catalogue, formfactor_dict, Exp_r, Exp_Gr, elements, xyz, SaveName=saveFits)\n",
    "    #Result = fitting_multiprocess(structure_catalogue, formfactor_dict, Exp_r, Exp_Gr, elements, xyz, SaveName=saveFits, cores=None)\n",
    "    Result_list[frame] = Result\n",
    "\n",
    "min_AtomContributionValue, max_AtomContributionValue = np.min(Result_list), np.max(Result_list)\n",
    "for frame in range(frames):\n",
    "    ### First define the experimental data path and the path you want the structure catalogue with fits to be saved\n",
    "    Experimental_Data = \"Experimental_Data/\"+StemName+\"_\"+str(frame)+\".gr\" # Name of the experimental file\n",
    "    saveFits = \"Training_Data/\"+StemName+str(frame)+\".txt\" # Name of the saved fits file\n",
    "    # Load data and start model\n",
    "    Exp_r, Exp_Gr, elements, xyz = Load(Experimental_Data, starting_model)\n",
    "    \n",
    "    # Step 3: Calculate Atom Contribution values\n",
    "    m, AtomContributionValues = calculate_atomContributionValue(Result_list[frame], min_AtomContributionValue, max_AtomContributionValue, saveResults, id_number=frame)\n",
    "    \n",
    "    # Step 4: Output a CrystalMaker file\n",
    "    Make_CrystalMakerFile(elements, xyz, AtomContributionValues, m, saveResults, id_number=frame)\n",
    "    \n",
    "print (time.time() - start_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
